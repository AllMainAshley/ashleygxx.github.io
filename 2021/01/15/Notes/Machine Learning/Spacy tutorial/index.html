<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="ç¨‹æµ·ç›"><meta name="copyright" content="ç¨‹æµ·ç›"><meta name="generator" content="Hexo 5.2.0"><meta name="theme" content="hexo-theme-yun"><title>Spacy tutorial | Ashley</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.25/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_dxory92pb0h.js" async></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script>document.addEventListener("DOMContentLoaded", () => {
  Yun.utils.renderKatex();
});</script><script src="https://cdn.jsdelivr.net/npm/pjax@latest/pjax.min.js" defer></script><script src="/js/pjax.js" defer></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><link rel="icon" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"allmainashley.github.io","root":"/","title":"ç›å§œè‘±èŠ±é±¼","version":"1.6.2","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}.","hits":"${hits} results found","hits_time":"${hits} results found in ${time} ms"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"local_search":{"path":"/search.xml"},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><link rel="alternate" href="/atom.xml" title="Ashley" type="application/atom+xml"><meta name="description" content="è¶…è¿‡95% çš„å†…å®¹æ¥è‡ªäºä¸€ç¯‡éå¸¸å…¨çš„ spacy æ•™ç¨‹ , å‰©ä½™5%çš„æ¥è‡ªäºæˆ‘åœ¨å®è·µè¿™ç¯‡æ•™ç¨‹ä¸­å‡ºçš„ä¸€äº›é”™è¯¯ä»¥åŠæ²¡æƒ³æ˜ç™½çš„é—®é¢˜ã€‚">
<meta property="og:type" content="article">
<meta property="og:title" content="Spacy tutorial">
<meta property="og:url" content="https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/index.html">
<meta property="og:site_name" content="Ashley">
<meta property="og:description" content="è¶…è¿‡95% çš„å†…å®¹æ¥è‡ªäºä¸€ç¯‡éå¸¸å…¨çš„ spacy æ•™ç¨‹ , å‰©ä½™5%çš„æ¥è‡ªäºæˆ‘åœ¨å®è·µè¿™ç¯‡æ•™ç¨‹ä¸­å‡ºçš„ä¸€äº›é”™è¯¯ä»¥åŠæ²¡æƒ³æ˜ç™½çš„é—®é¢˜ã€‚">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221038.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221506.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png">
<meta property="article:published_time" content="2021-01-15T13:28:29.344Z">
<meta property="article:modified_time" content="2021-01-15T15:09:14.735Z">
<meta property="article:author" content="ç¨‹æµ·ç›">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="Spacy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221038.png"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="Table of Contents"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="ç¨‹æµ·ç›"><img width="96" loading="lazy" src="/images/1.jpg" alt="ç¨‹æµ·ç›"><span class="site-author-status" title="Fall in love with lsh.">ğŸ’˜</span></a><div class="site-author-name"><a href="/about/">ç¨‹æµ·ç›</a></div><a class="site-name" href="/about/site.html">Ashley</a><sub class="site-subtitle">Face to new life and SAY HEY.</sub><div class="site-desciption">åšä¸ªå¿«ä¹çš„ç¬¨è›‹</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="Archives"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">21</span></a></div><div class="site-state-item"><a href="/categories/" title="Categories"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">10</span></a></div><div class="site-state-item"><a href="/tags/" title="Tags"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">22</span></a></div><a class="site-state-item hty-icon-button" href="/about/#comment" title="ç•™è¨€æ¿"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-clipboard-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/AllMainAshley" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:ashleyallmain@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="æˆ‘çš„å°ä¼™ä¼´ä»¬" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a><a class="links-item hty-icon-button" href="/girls/" title="å–œæ¬¢çš„å¥³å­©å­" style="color:hotpink"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-women-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Installation"><span class="toc-number">1.</span> <span class="toc-text">Installation</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Tutorial"><span class="toc-number">2.</span> <span class="toc-text">Tutorial</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Basic-processing"><span class="toc-number">2.1.</span> <span class="toc-text">Basic processing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Preprocessing"><span class="toc-number">2.2.</span> <span class="toc-text">Preprocessing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lemmatization"><span class="toc-number">2.3.</span> <span class="toc-text">Lemmatization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Strings-to-Hashes"><span class="toc-number">2.4.</span> <span class="toc-text">Strings to Hashes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Other-Token%E2%80%99s-Attributes"><span class="toc-number">2.5.</span> <span class="toc-text">Other Tokenâ€™s Attributes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Speech-Tags"><span class="toc-number">2.6.</span> <span class="toc-text">Speech Tags</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Named-Entity-Recognition"><span class="toc-number">2.7.</span> <span class="toc-text">Named Entity Recognition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Rule-based-Matching"><span class="toc-number">2.8.</span> <span class="toc-text">Rule based Matching</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Phrase-Matcher"><span class="toc-number">2.9.</span> <span class="toc-text">Phrase Matcher</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Entity-Ruler"><span class="toc-number">2.10.</span> <span class="toc-text">Entity Ruler</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Word-Vector-and-Similarity"><span class="toc-number">2.11.</span> <span class="toc-text">Word Vector and Similarity</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Merging-and-Splitting-Tokens-with-retokenize"><span class="toc-number">2.12.</span> <span class="toc-text">Merging and Splitting Tokens with retokenize</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pipeline-components"><span class="toc-number">2.13.</span> <span class="toc-text">Pipeline components </span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#References"><span class="toc-number">3.</span> <span class="toc-text">References</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Tutorials"><span class="toc-number">3.1.</span> <span class="toc-text">Tutorials</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Official-Documentation"><span class="toc-number">3.2.</span> <span class="toc-text">Official Documentation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CSDN-tutorials"><span class="toc-number">3.3.</span> <span class="toc-text">CSDN tutorials</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bugs"><span class="toc-number">3.4.</span> <span class="toc-text">Bugs</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="ç¨‹æµ·ç›"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Ashley"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Spacy tutorial</h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="Created: 2021-01-15 21:28:29" itemprop="dateCreated datePublished" datetime="2021-01-15T21:28:29+08:00">2021-01-15</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="Word count in article"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="Word count in article">4.4k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="Reading time"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="Reading time">23m</span></span></span><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/Tutorial/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">Tutorial</span></a></span> > <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/Tutorial/Machine-Learning/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">Machine Learning</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/NLP/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">NLP</span></a><a class="tag-item" href="/tags/Spacy/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">Spacy</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7;"><p>è¶…è¿‡95% çš„å†…å®¹æ¥è‡ªäº<a target="_blank" rel="noopener" href="https://www.machinelearningplus.com/spacy-tutorial-nlp/">ä¸€ç¯‡éå¸¸å…¨çš„ spacy æ•™ç¨‹</a> , å‰©ä½™5%çš„æ¥è‡ªäºæˆ‘åœ¨å®è·µè¿™ç¯‡æ•™ç¨‹ä¸­å‡ºçš„ä¸€äº›é”™è¯¯ä»¥åŠæ²¡æƒ³æ˜ç™½çš„é—®é¢˜ã€‚</p>
<a id="more"></a>

<h1 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h1><p><code>pip install spacy</code></p>
<p><code>python -m spacy download en</code>  ä¸‹è½½è¯­è¨€åŒ…</p>
<h1 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h1><h2 id="Basic-processing"><a href="#Basic-processing" class="headerlink" title="Basic processing"></a><font color=cornf>Basic processing</font></h2><ul>
<li><p>å¯¼å…¥æ¨¡å—</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_sm&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><font color=stbl>Docå¯¹è±¡</font>ä¸€ä¸ªæ ‡è®°åºåˆ—ï¼Œä¸ä»…åŒ…å«åŸå§‹æ–‡æœ¬ï¼Œè¿˜åŒ…å«spaCyæ¨¡å‹åœ¨å¤„ç†æ–‡æœ¬ä¹‹åäº§ç”Ÿçš„æ‰€æœ‰ç»“æœã€‚é¢„å…ˆè®¡ç®—æœ‰ç”¨çš„ä¿¡æ¯ï¼Œä¾‹å¦‚æ–‡æœ¬çš„å¼•ç†ï¼Œæ˜¯å¦æ˜¯åœç”¨è¯ï¼Œå‘½åå®ä½“ï¼Œæ–‡æœ¬çš„è¯å‘é‡ç­‰ï¼Œå¹¶å¾ˆå®¹æ˜“åœ°å­˜å‚¨åœ¨Docå¯¹è±¡ä¸­ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">my_text = <span class="string">&quot;&quot;&quot;The economic situation of the country is on edge , as the stock</span></span><br><span class="line"><span class="string">market crashed causing loss of millions. Citizens who had their main investment</span></span><br><span class="line"><span class="string">in the share-market are facing a great loss. Many companies might lay off</span></span><br><span class="line"><span class="string">thousands of people to reduce labor cost&quot;&quot;&quot;</span></span><br><span class="line">my_doc = nlp(my_text)</span><br></pre></td></tr></table></figure>
</li>
<li><p><font color=stbl>Token</font>æ˜¯ç»„æˆæ–‡æœ¬çš„å„ä¸ªæ–‡æœ¬å®ä½“ã€‚é€šå¸¸ï¼Œä»¤ç‰Œå¯ä»¥æ˜¯å•è¯ï¼Œæ ‡ç‚¹ç¬¦å·ï¼Œç©ºæ ¼ç­‰ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc:</span><br><span class="line">    print(token)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a><font color=cornf>Preprocessing</font></h2><ul>
<li><p>åˆ¤æ–­tokenæ˜¯å¦æ˜¯åœç”¨è¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc:</span><br><span class="line">    print(token.text,<span class="string">&#x27;--&#x27;</span>,token.is_stop,<span class="string">&#x27;---&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">The -- True ---</span><br><span class="line">economic -- False ---</span><br><span class="line">situation -- False ---</span><br><span class="line">of -- True ---</span><br><span class="line">the -- True ---</span><br><span class="line">country -- False ---</span><br><span class="line">is -- True ---</span><br><span class="line">on -- True ---</span><br><span class="line">edge -- False ---</span><br><span class="line">, -- False ---</span><br><span class="line">as -- True ---</span><br><span class="line">the -- True ---</span><br><span class="line">stock -- False ---</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
<li><p>æ¸…é™¤æ–‡æœ¬ä¸­çš„åœç”¨è¯å’Œæ ‡ç‚¹ç¬¦å·</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_doc_cleaned = [token <span class="keyword">for</span> token <span class="keyword">in</span> my_doc <span class="keyword">if</span> <span class="keyword">not</span> token.is_stop <span class="keyword">and</span> <span class="keyword">not</span> token.is_punct]</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc_cleaned:</span><br><span class="line">    print(token)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">economic</span><br><span class="line">situation</span><br><span class="line">country</span><br><span class="line">edge</span><br><span class="line">stock</span><br><span class="line"></span><br><span class="line">market</span><br><span class="line">crashed</span><br><span class="line">causing</span><br><span class="line">loss</span><br><span class="line">millions</span><br><span class="line">Citizens</span><br><span class="line">main</span><br><span class="line">investment</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>å¯¹æ–‡æœ¬è¿›è¡Œè¿™æ ·çš„é¢„å¤„ç†,æœ‰æ—¶å€™ç”šè‡³èƒ½å¤Ÿä½¿å¾—è¶…è¿‡ä¸€åŠçš„ä»¤ç‰Œè¢«åˆ é™¤ã€‚ä½¿å¤„ç†æ›´å¿«ï¼Œæ›´æœ‰æ„ä¹‰ã€‚</p>
</li>
</ul>
<h2 id="Lemmatization"><a href="#Lemmatization" class="headerlink" title="Lemmatization"></a><font color=cornf>Lemmatization</font></h2><p>ä¸¾ä¸ªä¾‹å­, â€œplayedâ€, â€œplayingâ€, â€œplaysâ€, â€œplayâ€ éƒ½æ˜¯æŒ‡å‘playçš„, æ‰€ä»¥å¯ä»¥é€šè¿‡tokençš„<code>lemma_</code>å±æ€§è®¿é—®åˆ°å…¶è¯æ ¹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&#x27;she played chess against rita she likes playing chess.&#x27;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.lemma_,token.lemma)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-PRON- 561228191312463089</span><br><span class="line">play 8228585124152053988</span><br><span class="line">chess 1107333712780441328</span><br><span class="line">against 16640565335581469180</span><br><span class="line">rita 11924181115131733150</span><br><span class="line">-PRON- 561228191312463089</span><br><span class="line">like 18194338103975822726</span><br><span class="line">play 8228585124152053988</span><br><span class="line">chess 1107333712780441328</span><br><span class="line">. 12646065887601541794</span><br></pre></td></tr></table></figure>

<p>âœ¨ å•è¯ <code>She</code>çš„ <code>lemma_</code> å±æ€§æ˜¯PRON, æ˜¯ä»£è¯çš„æ„æ€</p>
<h2 id="Strings-to-Hashes"><a href="#Strings-to-Hashes" class="headerlink" title="Strings to Hashes"></a><font color=cornf>Strings to Hashes</font></h2><ul>
<li><p>æ‰“å°å•è¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">doc1 = nlp(<span class="string">&#x27;Raymond shirts are famous&#x27;</span>)</span><br><span class="line">doc2 = nlp(<span class="string">&#x27;I washed my shirts&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;----------------DOC 1-----------------&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc1:</span><br><span class="line">    hash_value = nlp.vocab.strings[token.text]</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,hash_value)</span><br><span class="line">print(<span class="string">&#x27;----------------DOC 2-----------------&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc2:</span><br><span class="line">    hash_value = nlp.vocab.strings[token.text]</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,hash_value)</span><br></pre></td></tr></table></figure>

<p>æœ‰è¶£çš„æ˜¯ï¼Œä¸€ä¸ªå•è¯å°†å…·æœ‰ç›¸åŒçš„å“ˆå¸Œå€¼ï¼Œè€Œä¸ç®¡å®ƒå‡ºç°åœ¨å“ªä¸ªæ–‡æ¡£ä¸­æˆ–ä½¿ç”¨å“ªä¸ªspaCyæ¨¡å‹ã€‚å› æ­¤ï¼Œå³ä½¿æ‚¨åœ¨å…¶ä»–äººçš„è®¡ç®—æœºä¸Šè¿è¡Œä»£ç ï¼Œæ‚¨çš„ç»“æœä¹Ÿæ˜¯å¯é‡ç°çš„ã€‚</p>
</li>
</ul>
<h2 id="Other-Tokenâ€™s-Attributes"><a href="#Other-Tokenâ€™s-Attributes" class="headerlink" title="Other Tokenâ€™s Attributes"></a><font color=cornf>Other Tokenâ€™s Attributes</font></h2><ul>
<li><p>åªæ‰“å°æ•°å­—</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&#x27;2020 is far worse than 2009&#x27;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    <span class="keyword">if</span> token.like_num:</span><br><span class="line">        print(token)</span><br></pre></td></tr></table></figure>
</li>
<li><p>åªåˆ—å‡ºç™¾åˆ†æ¯”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">production_text=<span class="string">&#x27; Production in chennai is 87 %. In Kolkata, produce it as low as 43 %. In Bangalore, production ia as good as 98 %.In mysore, production is average around 78 %&#x27;</span></span><br><span class="line">doc = nlp(production_text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    <span class="keyword">if</span> token.like_num:</span><br><span class="line">        next_token_index = token.i +<span class="number">1</span></span><br><span class="line">        next_token = doc[next_token_index]</span><br><span class="line">        <span class="keyword">if</span> next_token.text == <span class="string">&#x27;%&#x27;</span>:</span><br><span class="line">            print(token.text)</span><br></pre></td></tr></table></figure>

<p>ç¬¬<code>i</code>ä¸ªtokenå¦‚æœæ˜¯æ•°å­—å¹¶ä¸”ç¬¬<code>i+1</code>ä¸ªtokenæ˜¯<code>%</code>ï¼Œåˆ™å®ƒæ˜¯ç™¾åˆ†æ¯”ï¼Œå¯ä»¥æ‰“å°</p>
</li>
<li><p>åªåˆ—å‡ºç”µå­é‚®ä»¶</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">employee_text=<span class="string">&quot;&quot;&quot; name : Koushiki age: 45 email : koushiki@gmail.com</span></span><br><span class="line"><span class="string">                 name : Gayathri age: 34 email: gayathri1999@gmail.com</span></span><br><span class="line"><span class="string">                 name : Ardra age: 60 email : ardra@gmail.com</span></span><br><span class="line"><span class="string">                 name : pratham parmar age: 15 email : parmar15@yahoo.com</span></span><br><span class="line"><span class="string">                 name : Shashank age: 54 email: shank@rediffmail.com</span></span><br><span class="line"><span class="string">                 name : Utkarsh age: 46 email :utkarsh@gmail.com&quot;&quot;&quot;</span></span><br><span class="line">employee_doc = nlp(employee_text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> employee_doc:</span><br><span class="line">    <span class="keyword">if</span> token.like_email:</span><br><span class="line">        print(token.text)</span><br></pre></td></tr></table></figure>
</li>
<li><p>åŒæ ·ï¼ŒspaCyæä¾›äº†å„ç§ä»¤ç‰Œå±æ€§ã€‚ä»¥ä¸‹æ˜¯è¿™äº›å±æ€§åŠå…¶æ‰§è¡Œçš„åŠŸèƒ½çš„åˆ—è¡¨:</p>
<ul>
<li><code>token.is_alpha</code>ï¼šè¿”å›<code>True</code>ä»¤ç‰Œæ˜¯å¦ä¸ºå­—æ¯</li>
<li><code>token.is_ascii</code>ï¼šè¿”å›<code>True</code>ä»¤ç‰Œæ˜¯å¦å±äºASCIIå­—ç¬¦</li>
<li><code>token.is_digit</code>ï¼šè¿”å›<code>True</code>ä»¤ç‰Œæ˜¯å¦ä¸ºæ•°å­—ï¼ˆ0-9ï¼‰</li>
<li><code>token.is_upper</code>ï¼šè¿”å›<code>True</code>ä»¤ç‰Œæ˜¯å¦ä¸ºå¤§å†™å­—æ¯</li>
<li><code>token.is_lower</code>ï¼šè¿”å›<code>True</code>ä»¤ç‰Œæ˜¯å¦ä¸ºå°å†™å­—æ¯</li>
<li><code>token.is_space</code>ï¼šè¿”å›<code>True</code>ä»¤ç‰Œæ˜¯å¦ä¸ºç©ºæ ¼â€™â€™</li>
<li><code>token.is_bracket</code>ï¼šè¿”å›<code>True</code>ä»¤ç‰Œæ˜¯å¦ä¸ºæ‹¬å·</li>
<li><code>token.is_quote</code>ï¼šè¿”å›<code>True</code>ä»¤ç‰Œæ˜¯å¦ä¸ºå¼•å·</li>
<li><code>token.like_url</code>ï¼šè¿”å›<code>True</code>ä»¤ç‰Œæ˜¯å¦ç±»ä¼¼äºURlï¼ˆé“¾æ¥åˆ°ç½‘ç«™ï¼‰</li>
</ul>
</li>
</ul>
<h2 id="Speech-Tags"><a href="#Speech-Tags" class="headerlink" title="Speech Tags"></a><font color=cornf>Speech Tags</font></h2><ul>
<li><p>æ‰“å°å‡ºæ‰€æœ‰tokençš„è¯æ€§æ ‡ç­¾</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my_text=<span class="string">&#x27;John plays basketball,if time permits. He played in high school too.&#x27;</span></span><br><span class="line">my_doc = nlp(my_text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc:</span><br><span class="line">    print(token.text,<span class="string">&#x27;--------&#x27;</span>,token.pos_)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">John -------- PROPN</span><br><span class="line">plays -------- VERB</span><br><span class="line">basketball -------- NOUN</span><br><span class="line">, -------- PUNCT</span><br><span class="line">if -------- SCONJ</span><br><span class="line">time -------- NOUN</span><br><span class="line">permits -------- VERB</span><br><span class="line">. -------- PUNCT</span><br><span class="line">He -------- PRON</span><br><span class="line">played -------- VERB</span><br><span class="line">in -------- ADP</span><br><span class="line">high -------- ADJ</span><br><span class="line">school -------- NOUN</span><br><span class="line">too -------- ADV</span><br><span class="line">. -------- PUNCT</span><br></pre></td></tr></table></figure>
</li>
<li><p>è§£é‡Šæ ‡ç­¾</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spacy.explain(<span class="string">&#x27;SCONJ&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#39;subordinating conjunction&#39;</span><br></pre></td></tr></table></figure>
</li>
<li><p>ä½¿ç”¨spacyçš„<code>pos_</code>å±æ€§ï¼Œæ‚¨å¯ä»¥æ£€æŸ¥ç‰¹å®šä»¤ç‰Œæ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶å¹¶åˆ é™¤ã€‚(åˆ é™¤ç±»ä¼¼<code>etc</code>, <code>i.e.</code>ç­‰è¯æ±‡)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">raw_text=<span class="string">&quot;&quot;&quot;I liked the movies etc The movie had good direction  The movie was amazing i.e.</span></span><br><span class="line"><span class="string">            The movie was average direction was not bad The cinematography was nice. i.e.</span></span><br><span class="line"><span class="string">            The movie was a bit lengthy  otherwise fantastic  etc etc&quot;&quot;&quot;</span></span><br><span class="line">raw_doc = nlp(raw_text)</span><br><span class="line">print(<span class="string">&#x27;The junk value are...&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> raw_doc:</span><br><span class="line">    <span class="keyword">if</span> token.pos_==<span class="string">&#x27;X&#x27;</span>:</span><br><span class="line">        print(token.text)</span><br><span class="line">cleaned_doc = [token <span class="keyword">for</span> token <span class="keyword">in</span> raw_doc <span class="keyword">if</span> <span class="keyword">not</span> token.pos_ == <span class="string">&#x27;X&#x27;</span>]</span><br><span class="line">print(cleaned_doc)</span><br></pre></td></tr></table></figure>
</li>
<li><p>æŸ¥çœ‹æ‰€æœ‰æ ‡ç­¾</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_tags =  &#123;token.pos: token.pos_ <span class="keyword">for</span> token <span class="keyword">in</span> raw_doc&#125;</span><br><span class="line">print(all_tags)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Named-Entity-Recognition"><a href="#Named-Entity-Recognition" class="headerlink" title="Named Entity Recognition"></a><font color=cornf>Named Entity Recognition</font></h2><ul>
<li><p>å®ä½“å‘½åè¯†åˆ«</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&#x27;Tony Stark owns the company StarkEnterprises . Emily Clark works at Microsoft and lives in Manchester. She loves to read the Bible and learn French&#x27;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line">print(doc.ents)</span><br><span class="line"><span class="keyword">for</span> entity <span class="keyword">in</span> doc.ents:</span><br><span class="line">    print(entity.text,<span class="string">&#x27;-------&#x27;</span>,entity.label_)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(Tony Stark, StarkEnterprises, Emily Clark, Microsoft, Manchester, Bible, French)</span><br><span class="line">Tony Stark ------- PERSON</span><br><span class="line">StarkEnterprises ------- ORG</span><br><span class="line">Emily Clark ------- PERSON</span><br><span class="line">Microsoft ------- ORG</span><br><span class="line">Manchester ------- GPE</span><br><span class="line">Bible ------- WORK_OF_ART</span><br><span class="line">French ------- NORP</span><br></pre></td></tr></table></figure>

<p>æ¯ä¸ªå‘½åå®ä½“éƒ½å±äºä¸€ä¸ªç±»åˆ«ï¼Œä¾‹å¦‚äººåï¼Œç»„ç»‡æˆ–åŸå¸‚ç­‰ã€‚spacyæ”¯æŒçš„å¸¸è§å‘½åå®ä½“ç±»åˆ«ä¸ºï¼š</p>
<ul>
<li><code>PERSON</code> ï¼šä»£è¡¨äººå</li>
<li><code>GPE</code> ï¼šè¡¨ç¤ºå¿ï¼ŒåŸå¸‚ï¼Œå·ç­‰åœ°æ–¹ã€‚</li>
<li><code>ORG</code> ï¼šè¡¨ç¤ºç»„ç»‡æˆ–å…¬å¸</li>
<li><code>WORK_OF_ART</code> ï¼šè¡¨ç¤ºä¹¦ç±ï¼Œç”µå½±ï¼Œæ­Œæ›²å’Œå…¶ä»–è‰ºæœ¯çš„æ ‡é¢˜</li>
<li><code>PRODUCT</code> ï¼šè¡¨ç¤ºè½¦è¾†ï¼Œé£Ÿå“ï¼Œå®¶å…·ç­‰äº§å“ã€‚</li>
<li><code>EVENT</code> ï¼šè¡¨ç¤ºæˆ˜äº‰ï¼Œç¾éš¾ç­‰å†å²äº‹ä»¶â€¦</li>
<li><code>LANGUAGE</code> ï¼šå…¨çƒæ‰€æœ‰å…¬è®¤çš„è¯­è¨€ã€‚</li>
</ul>
</li>
<li><p>å¯è§†åŒ–</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy <span class="keyword">import</span> displacy</span><br><span class="line">displacy.render(doc,style=<span class="string">&#x27;ent&#x27;</span>,jupyter=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221038.png" loading="lazy"></p>
</li>
<li><p>æå–å“ç‰Œåç§°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mobile_industry_article=<span class="string">&quot;&quot;&quot; 30 Major mobile phone brands Compete in India â€“ A Case Study of Success and Failures</span></span><br><span class="line"><span class="string">Is the Indian mobile market a terrible War Zone? We have more than 30 brands competing with each other. Letâ€™s find out some insights about the world second-largest mobile bazaar.There is a massive invasion by Chinese mobile brands in India in the last four years. Some of the brands have been able to make a mark while others like Meizu, Coolpad, ZTE, and LeEco are a failure.On one side, there are brands like Sony or HTC that have quit from the Indian market on the other side we have new brands like Realme or iQOO entering the marketing in recent months.The mobile market is so competitive that some of the brands like Micromax, which had over 18% share back in 2014, now have less than 5%. Even the market leader Samsung with a 34% market share in 2014, now has a 21% share whereas Xiaomi has become a market leader. The battle is fierce and to sustain and scale-up is going to be very difficult for any new entrant.new comers in Indian Mobile MarketiQOO â€“They have recently (March 2020) launched the iQOO 3 in India with its first 5G phone â€“ iQOO 3. The new brand is part of the Vivo or the BBK electronics group that also owns several other brands like Oppo, Oneplus and Realme.Realme â€“ Realme launched the first-ever phone â€“ Realme 1 in November 2018 and has quickly became a popular brand in India. The brand is one of the highest sellers in online space and even reached a 16% market share threatening Xiaomiâ€™s dominance.iVoomi â€“ In 2017, we have seen the entry of some new Chinese mobile brands likeiVoomi which focuses on the sub 10k price range, and is a popular online player. They have an association with Flipkart.Techno &amp;amp; Infinix â€“ Transsion Groupâ€™s Tecno and Infinix brands debuted in India in mid-2017 and are focusing on the low end and mid-range phones in the price range of Rs. 5000 to Rs. 12000.10.OR &amp;amp; Lephone â€“ 10.OR has a partnership with Amazon India and is an exclusive online brand with phones like 10.OR D, G and E. However, the brand is not very aggressive currently.Kult â€“ Kult is another player who launched a very aggressively priced Kult Beyond mobile in 2017 and followed up by launching 2-3 more models.However, most of these new brands are finding it difficult to strengthen their footing in India. As big brands like Xiaomi leave no stone unturned to make things difficult.Also, it is worth noting that there is less Chinese players coming to India now. As either all the big brands have already set shop or burnt their hands and retreated to the homeland China.Chinese/ Global  Brands Which failed or are at the Verge of Failing in India?</span></span><br><span class="line"><span class="string">There are a lot more failures in the market than the success stories. Letâ€™s first look at the failures and then we will also discuss why some brands were able to succeed in India.HTC â€“ The biggest surprise this year for me was the failure of HTC in India. The brand has been in the country for many years, in fact, they were the first brand to launch Android mobiles. Finally HTC decided to call it a day in July 2018.LeEco â€“ LeEco looked promising and even threatening to Xiaomi when it came to India. The company launched a series of new phones and smart TVs at affordable rates. Unfortunately, poor financial planning back home caused the brand to fail in India too.LG â€“ The company seems to have lost focus and are doing poorly in all segments. While the budget and mid-range offering are uncompetitive, the high-end models are not preferred by buyers.Sony â€“ Absurd pricing and lack of ability to understand the Indian buyers have caused Sony to shrink mobile operations in India. In the last 2 years, there are far fewer launches and hardly any promotions or hype around the new products.Meizu â€“ Meizu is also a struggling brand in India and is going nowhere with the current strategy. There are hardly any popular mobiles nor a retail presence.ZTE â€“ The company was aggressive till last year with several new phones launching under the Nubia banner, but with recent issues in the US, they have even lost the plot in India.Coolpad â€“ I still remember the first meeting with Coolpad CEO in Mumbai when the brand started operations. There were big dreams and ambitions, but the company has not been able to deliver and keep up with the rivals in the last 1 year.Gionee â€“ Gionee was doing well in the retail, but the infighting in the company and loss of focus from the Chinese parent company has made it a failure. The company is planning a comeback. However, we will have to wait and see when that happens.&quot;&quot;&quot;</span></span><br><span class="line">mobile_doc = nlp(mobile_industry_article)</span><br><span class="line">list_of_org = []</span><br><span class="line"><span class="keyword">for</span> entity <span class="keyword">in</span> mobile_doc.ents:</span><br><span class="line">    <span class="keyword">if</span> entity.label_ == <span class="string">&#x27;ORG&#x27;</span>:</span><br><span class="line">        list_of_org.append(entity.text)</span><br><span class="line">print(list_of_org)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#39;Meizu&#39;, &#39;Sony&#39;, &#39;Vivo&#39;, &#39;Xiaomi&#39;, &#39;Flipkart&#39;, &#39;Techno &amp;amp&#39;, &#39;Infinix â€“ Transsion Group&#39;, &#39;12000.10.OR &amp;amp&#39;, &#39;Lephone&#39;, &#39;Amazon India&#39;, &#39;Global  Brands&#39;, &#39;the Verge of Failing&#39;, &#39;Sony&#39;, &#39;Sony&#39;, &#39;Meizu&#39;, &#39;Meizu&#39;, &#39;Nubia&#39;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>è‡ªåŠ¨æ©ç›–å®ä½“</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">news_text=<span class="string">&quot;&quot;&quot;Indian man has allegedly duped nearly 50 businessmen in the UAE of USD 1.6 million and fled the country in the most unlikely way -- on a repatriation flight to Hyderabad, according to a media report on Saturday.Yogesh Ashok Yariava, the prime accused in the fraud, flew from Abu Dhabi to Hyderabad on a Vande Bharat repatriation flight on May 11 with around 170 evacuees, the Gulf News reported.Yariava, the 36-year-old owner of the fraudulent Royal Luck Foodstuff Trading, made bulk purchases worth 6 million dirhams (USD 1.6 million) against post-dated cheques from unsuspecting traders before fleeing to India, the daily said.</span></span><br><span class="line"><span class="string">The bought goods included facemasks, hand sanitisers, medical gloves (worth nearly 5,00,000 dirhams), rice and nuts (3,93,000 dirhams), tuna, pistachios and saffron (3,00,725 dirhams), French fries and mozzarella cheese (2,29,000 dirhams), frozen Indian beef (2,07,000 dirhams) and halwa and tahina (52,812 dirhams).</span></span><br><span class="line"><span class="string">The list of items and defrauded persons keeps getting longer as more and more victims come forward, the report said.</span></span><br><span class="line"><span class="string">The aggrieved traders have filed a case with the Bur Dubai police station.</span></span><br><span class="line"><span class="string">The traders said when the dud cheques started bouncing they rushed to the Royal Luck&#x27;s office in Dubai but the shutters were down, even the fraudulent company&#x27;s warehouses were empty.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">news_doc=nlp(news_text)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_details</span>(<span class="params">word</span>):</span></span><br><span class="line">  <span class="keyword">if</span> word.ent_type_ ==<span class="string">&#x27;PERSON&#x27;</span> <span class="keyword">or</span> word.ent_type_==<span class="string">&#x27;ORG&#x27;</span> <span class="keyword">or</span> word.ent_type_==<span class="string">&#x27;GPE&#x27;</span>:</span><br><span class="line">    print(word,<span class="string">&#x27;-----&#x27;</span>,word.ent_type_)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; UNKNOWN &#x27;</span></span><br><span class="line">  <span class="keyword">return</span> word.string</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_article</span>(<span class="params">doc</span>):</span></span><br><span class="line">    <span class="keyword">for</span> ent <span class="keyword">in</span> doc.ents:</span><br><span class="line">        ent.merge()</span><br><span class="line">        <span class="comment"># Iterate over all spans and merge them into one token. This is done</span></span><br><span class="line">        <span class="comment"># after setting the entities â€“ otherwise, it would cause mismatched indices!</span></span><br><span class="line">    tokens = map(remove_details,doc)</span><br><span class="line">    <span class="comment"># mapå‡½æ•°ï¼šç¬¬ä¸€ä¸ªå‚æ•°æ¥å—ä¸€ä¸ªå‡½æ•°åï¼Œåé¢çš„å‚æ•°æ¥å—ä¸€ä¸ªæˆ–å¤šä¸ªå¯è¿­ä»£çš„åºåˆ—ï¼Œè¿”å›çš„æ˜¯ä¸€ä¸ªé›†åˆã€‚</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(tokens)</span><br><span class="line">update_article(news_doc)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœ: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;Indian man has allegedly duped nearly 50 businessmen in the UAE of USD 1.6 million and fled the country in the most unlikely way -- on a repatriation flight to  UNKNOWN , according to a media report on Saturday. UNKNOWN , the prime accused in the fraud, flew from  UNKNOWN to  UNKNOWN on a Vande Bharat repatriation flight on May 11 with around 170 evacuees,  UNKNOWN reported. UNKNOWN , the 36-year-old owner of the fraudulent Royal Luck Foodstuff Trading, made bulk purchases worth 6 million dirhams (USD 1.6 million) against post-dated cheques from unsuspecting traders before fleeing to  UNKNOWN , the daily said.\nThe bought goods included facemasks, hand sanitisers, medical gloves (worth nearly 5,00,000 dirhams), rice and nuts (3,93,000 dirhams), tuna, pistachios and saffron (3,00,725 dirhams), French fries and mozzarella cheese (2,29,000 dirhams), frozen Indian beef (2,07,000 dirhams) and halwa and tahina (52,812 dirhams).\nThe list of items and defrauded persons keeps getting longer as more and more victims come forward, the report said.\nThe aggrieved traders have filed a case with the  UNKNOWN police station.\nThe traders said when the dud cheques started bouncing they rushed to  UNKNOWN office in  UNKNOWN but the shutters were down, even the fraudulent company&#39;s warehouses were empty.&quot;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Rule-based-Matching"><a href="#Rule-based-Matching" class="headerlink" title="Rule based Matching"></a><font color=cornf>Rule based Matching</font></h2><ul>
<li><p>å¯¼å…¥æ¨¡å‹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy.matcher <span class="keyword">import</span> Matcher</span><br></pre></td></tr></table></figure>
</li>
<li><p>è¿‡ç¨‹</p>
<p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221506.png" loading="lazy"></p>
</li>
</ul>
<ul>
<li><p>æ¨¡å¼åŒ¹é… <code>Example1</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">my_text = <span class="string">&#x27;The version : 6 of the app was released about a year back and was not very sucessful. As a comeback, six months ago, version : 7 was released and it took the stage. After that , the app has has the limelight till now. On interviewing some sources, we get to know that they have outlined visiond till version : 12 ,the Ultimate.&#x27;</span></span><br><span class="line">my_doc = nlp(my_text)</span><br><span class="line"></span><br><span class="line">my_pattern = [&#123;<span class="string">&quot;LOWER&quot;</span>:<span class="string">&quot;version&quot;</span>&#125;,&#123;<span class="string">&quot;IS_PUNCT&quot;</span>:<span class="literal">True</span>&#125;,&#123;<span class="string">&quot;LIKE_NUM&quot;</span>:<span class="literal">True</span>&#125;]</span><br><span class="line">mather.add(<span class="string">&#x27;VersionFinder&#x27;</span>,<span class="literal">None</span>,my_pattern)</span><br><span class="line">desired_matches = mather(my_doc)</span><br><span class="line">desired_matches</span><br></pre></td></tr></table></figure>

<p>æ‰“å°desired_matchesçš„ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[(6950581368505071052, 1, 4),</span><br><span class="line"> (6950581368505071052, 27, 30),</span><br><span class="line"> (6950581368505071052, 65, 68)]</span><br></pre></td></tr></table></figure>

<p>æ‰“å°å‡ºæ‰¾åˆ°çš„token:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> match_id,start,end <span class="keyword">in</span> desired_matches:</span><br><span class="line">    string_id = nlp.vocab.strings[match_id]</span><br><span class="line">    span = my_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">version : 6</span><br><span class="line">version : 7</span><br><span class="line">version : 12</span><br></pre></td></tr></table></figure>
</li>
<li><p>æ¨¡å¼è¯†åˆ« <code>Example 2</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&quot;&quot;&quot;I visited Manali last time. Around same budget trips ? &quot;</span></span><br><span class="line"><span class="string">    I was visiting Ladakh this summer &quot;</span></span><br><span class="line"><span class="string">    I have planned visiting NewYork and other abroad places for next year&quot;</span></span><br><span class="line"><span class="string">    Have you ever visited Kodaikanal? &quot;&quot;&quot;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line">mather = Matcher(nlp.vocab)</span><br><span class="line">my_pattern = [&#123;<span class="string">&quot;LEMMA&quot;</span>: <span class="string">&quot;visit&quot;</span>&#125;, &#123;<span class="string">&quot;POS&quot;</span>: <span class="string">&quot;PROPN&quot;</span>&#125;]</span><br><span class="line">mather.add(<span class="string">&#x27;PlaceFinder&#x27;</span>,<span class="literal">None</span>,my_pattern)</span><br><span class="line">matches = mather(doc)</span><br><span class="line">print(<span class="string">&quot; mather found: &quot;</span>,len(matches))</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> matches:</span><br><span class="line">    print(<span class="string">&#x27;Match Found:&#x27;</span>,doc[start:end].text)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mather found:  4</span><br><span class="line">Match Found: visited Manali</span><br><span class="line">Match Found: visiting Ladakh</span><br><span class="line">Match Found: visiting NewYork</span><br><span class="line">Match Found: visited Kodaikanal</span><br></pre></td></tr></table></figure>
</li>
<li><p>å¤æ‚çš„åŒ¹é…æ¡ä»¶: å…¶ä¸­ç¬¬ä¸€ä¸ªä»¤ç‰Œå…·æœ‰POSæ ‡è®°ä¸ºNOUNæˆ–ADJçš„æ¡ä»¶, ç¬¬äºŒä¸ªtokenä¸º<code>engineering</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my_pattern = [&#123;<span class="string">&quot;POS&quot;</span>: &#123;<span class="string">&quot;IN&quot;</span>: [<span class="string">&quot;NOUN&quot;</span>, <span class="string">&quot;ADJ&quot;</span>]&#125;&#125;, &#123;<span class="string">&quot;LOWER&quot;</span>: <span class="string">&quot;engineering&quot;</span>&#125;]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Phrase-Matcher"><a href="#Phrase-Matcher" class="headerlink" title="Phrase Matcher"></a><font color=cornf>Phrase Matcher</font></h2><ul>
<li><p>å¯¼å…¥æ¨¡å—</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy.matcher <span class="keyword">import</span> PhraseMatcher</span><br></pre></td></tr></table></figure>
</li>
<li><p>å®šä¹‰æ¨¡å¼</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">matcher = PhraseMatcher(nlp.vocab)</span><br><span class="line">terms_list = [<span class="string">&#x27;Bruce Wayne&#x27;</span>, <span class="string">&#x27;Tony Stark&#x27;</span>, <span class="string">&#x27;Batman&#x27;</span>, <span class="string">&#x27;Harry Potter&#x27;</span>, <span class="string">&#x27;Severus Snape&#x27;</span>]</span><br><span class="line">patterns = [nlp.make_doc(text) <span class="keyword">for</span> text <span class="keyword">in</span> terms_list]</span><br><span class="line"><span class="comment"># å°†çŸ­è¯­åˆ—è¡¨è½¬æ¢ä¸ºdocå¯¹è±¡ã€‚å®ƒæ›´å¿«å¹¶ä¸”èŠ‚çœæ—¶é—´ã€‚make_doc()</span></span><br><span class="line">matcher.add(<span class="string">&#x27;phrase_matcher&#x27;</span>,<span class="literal">None</span>,*patterns)</span><br><span class="line"></span><br><span class="line">matches = matcher(doc)</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> matches:</span><br><span class="line">    span = fictional_char_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœ:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Batman</span><br><span class="line">Batman</span><br><span class="line">Harry Potter</span><br><span class="line">Harry Potter</span><br><span class="line">Tony Stark</span><br></pre></td></tr></table></figure>

<p>å¯ä»¥å‘ç°å°å†™å•è¯çš„æ— æ³•è¯†åˆ«å‡ºæ¥, é‚£ä¹ˆåšä¸€ä¸‹æ”¹è¿›</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">matcher = PhraseMatcher(nlp.vocab,attr=<span class="string">&#x27;LOWER&#x27;</span>)</span><br><span class="line"><span class="comment"># å¦‚æœä½¿ç”¨ï¼Œåˆ™å°†å‘ç”Ÿä¸åŒºåˆ†å¤§å°å†™çš„åŒ¹é…ã€‚attr=&#x27;LOWER&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ä¸¾ä¸ªä¾‹å­</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">case_insensitive_matcher = PhraseMatcher(nlp.vocab,attr=<span class="string">&#x27;LOWER&#x27;</span>)</span><br><span class="line">my_doc = nlp(<span class="string">&#x27;I wish to visit new york city.&#x27;</span>)</span><br><span class="line">terms_list = [<span class="string">&#x27;New York&#x27;</span>]</span><br><span class="line">patterns = [nlp.make_doc(text) <span class="keyword">for</span> text <span class="keyword">in</span> terms_list]</span><br><span class="line">case_insensitive_matcher.add(<span class="string">&#x27;mather&#x27;</span>,<span class="literal">None</span>,*patterns)</span><br><span class="line">my_matches = case_insensitive_matcher(my_doc)</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> my_matches:</span><br><span class="line">    span = my_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœ:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new york</span><br></pre></td></tr></table></figure>
</li>
<li><p>åŒ¹é…å°†åŸºäºpatternä¸­æœ¯è¯­çš„å½¢çŠ¶ã€‚<code>attr=&#39;SHAPE&#39;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">my_doc = nlp(<span class="string">&#x27;From 8 am , Mr.X will be speaking on your favorite chanel 191.1. Afterward there shall be an exclusive interview with actor Vijay on channel 194.1 . Hope you are having a great day. Call us on 666666&#x27;</span>)</span><br><span class="line">pattern = nlp(<span class="string">&#x27;154.6&#x27;</span>)</span><br><span class="line">pincode_matcher = PhraseMatcher(nlp.vocab,attr=<span class="string">&#x27;SHAPE&#x27;</span>)</span><br><span class="line">pincode_matcher.add(<span class="string">&#x27;pincode_matching&#x27;</span>,<span class="literal">None</span>,pattern)</span><br><span class="line">matches = pincode_matcher(my_doc)</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> matches:</span><br><span class="line">    span = my_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœ:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">191.1</span><br><span class="line">194.1</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Entity-Ruler"><a href="#Entity-Ruler" class="headerlink" title="Entity Ruler"></a><font color=cornf>Entity Ruler</font></h2><ul>
<li><p>é»˜è®¤æƒ…å†µä¸‹æ— æ³•è¯†åˆ«æŸäº›åç§°æˆ–ç»„ç»‡ã€‚å¯èƒ½æ˜¯å› ä¸ºå®ƒä»¬è§„æ¨¡å¾ˆå°æˆ–ç¨€æœ‰ã€‚ä½¿ç”¨EnityRuler, åŸºäºæ¨¡å¼è¯å…¸åŒ¹é…å‘½åå®ä½“, ä»è€Œä½¿å‘½åå®ä½“è¯†åˆ«æ›´åŠ æœ‰æ•ˆ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy.pipeline <span class="keyword">import</span> EntityRuler</span><br><span class="line">ruler = EntityRuler(nlp)</span><br><span class="line">pattern=[&#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;WORK_OF_ART&quot;</span>, <span class="string">&quot;pattern&quot;</span>: <span class="string">&quot;My guide to statistics&quot;</span>&#125;]</span><br><span class="line">ruler.name = <span class="string">&#x27;new_ruler&#x27;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ruler.add_patterns(pattern)</span><br><span class="line">nlp.add_pipe(ruler)</span><br><span class="line"><span class="comment"># ç°åœ¨ï¼ŒEntityRulerå·²åˆå¹¶åˆ°ä¸­nlpã€‚æ‚¨å¯ä»¥å°†æ–‡æœ¬æ–‡æ¡£ä¼ é€’nlpç»™ä»¥åˆ›å»ºspacy docã€‚</span></span><br><span class="line">doc = nlp(<span class="string">&quot; I recently published my work fanfiction by Dr.X . Right now I&#x27;m studying the book of my friend .You should try My guide to statistics for clear concepts.&quot;</span>)</span><br><span class="line">print([(ent.text,ent.label_) <span class="keyword">for</span> ent <span class="keyword">in</span> doc.ents])</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(&#39;My guide to statistics&#39;, &#39;WORK_OF_ART&#39;)]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Word-Vector-and-Similarity"><a href="#Word-Vector-and-Similarity" class="headerlink" title="Word Vector and Similarity"></a><font color=cornf>Word Vector and Similarity</font></h2><ul>
<li><p>å•è¯å‘é‡: <code>token.has_vector</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_md&quot;</span>)</span><br><span class="line">doc = nlp(<span class="string">&quot;Iã€€am a excellent people&quot;</span>)</span><br><span class="line">doc_another = nlp(<span class="string">&quot;I wish to go to hogwarts lolXD&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,token.has_vector)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc_another:</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,token.has_vector)</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,token.vector_norm)	<span class="comment"># è¡¨ç¤ºL2èŒƒæ•°</span></span><br><span class="line">    print(<span class="string">&#x27;------------------------------&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">I   True</span><br><span class="line">I   6.4231944</span><br><span class="line">------------------------------</span><br><span class="line">wish   True</span><br><span class="line">wish   5.1652417</span><br><span class="line">------------------------------</span><br><span class="line">to   True</span><br><span class="line">to   4.74484</span><br><span class="line">------------------------------</span><br><span class="line">go   True</span><br><span class="line">go   5.05723</span><br><span class="line">------------------------------</span><br><span class="line">to   True</span><br><span class="line">to   4.74484</span><br><span class="line">------------------------------</span><br><span class="line">hogwarts   True</span><br><span class="line">hogwarts   7.4110312</span><br><span class="line">------------------------------</span><br><span class="line">lolXD   False</span><br><span class="line">lolXD   0.0</span><br><span class="line">------------------------------</span><br></pre></td></tr></table></figure>
</li>
<li><p>å•è¯ç›¸ä¼¼æ€§</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">review_1=nlp(<span class="string">&#x27; The food was amazing&#x27;</span>)</span><br><span class="line">review_2=nlp(<span class="string">&#x27;The food was excellent&#x27;</span>)</span><br><span class="line">review_3=nlp(<span class="string">&#x27;I did not like the food&#x27;</span>)</span><br><span class="line">review_4=nlp(<span class="string">&#x27;It was very bad experience&#x27;</span>)</span><br><span class="line">score_1 = review_1.similarity(review_2)</span><br><span class="line">print(score_1)</span><br><span class="line">score_2 = review_3.similarity(review_4)</span><br><span class="line">print(score_2)</span><br><span class="line"><span class="comment"># æ‚¨ä¼šçœ‹åˆ°å‰ä¸¤ä¸ªè¯„è®ºå…·æœ‰å¾ˆé«˜çš„ç›¸ä¼¼æ€§è¯„åˆ†ï¼Œå› æ­¤å°†å±äºåŒä¸€ç±»åˆ«ï¼ˆæ­£é¢ï¼‰ã€‚</span></span><br><span class="line"><span class="comment"># æ•°å€¼å¾ˆä½åˆ™ä»£è¡¨å®Œå…¨ä¸ç›¸å…³</span></span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.9566209228174343</span><br><span class="line">0.8461895934074601</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Merging-and-Splitting-Tokens-with-retokenize"><a href="#Merging-and-Splitting-Tokens-with-retokenize" class="headerlink" title="Merging and Splitting Tokens with retokenize"></a><font color=cornf>Merging and Splitting Tokens with retokenize</font></h2><ul>
<li><p>ç»„åˆä»¤ç‰Œï¼šset the <code>POS</code> (part of speech tag) for â€œJohn Wickâ€ as <code>PROPN</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»è¾“å‡ºä¸­å¯ä»¥çœ‹åˆ°ï¼Œâ€œ Johnâ€å’Œâ€œ Wickâ€å·²è¢«è¯†åˆ«ä¸ºå•ç‹¬çš„æ ‡è®°ã€‚å¯¼æ¼”çš„åå­—â€œ Chad Stahelskiâ€ä¹Ÿæ˜¯å¦‚æ­¤</span></span><br><span class="line"><span class="comment"># ä½†æ˜¯åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœå°†â€œ John Wickâ€è§†ä¸ºå•ä¸ªä»¤ç‰Œï¼Œå°†æ›´åŠ å®¹æ˜“ã€‚</span></span><br><span class="line">text = <span class="string">&quot;John Wick is a 2014 American action thriller film directed by Chad Stahelski&quot;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"><span class="keyword">with</span> doc.retokenize() <span class="keyword">as</span> retokenizer:</span><br><span class="line">    attrs = &#123;<span class="string">&quot;POS&quot;</span>:<span class="string">&quot;PROPN&quot;</span>&#125;</span><br><span class="line">    retokenizer.merge(doc[<span class="number">0</span>:<span class="number">2</span>],attrs)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text,token.pos_)</span><br></pre></td></tr></table></figure>

<p>æ‰“å°ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">John Wick PROPN</span><br><span class="line">is AUX</span><br><span class="line">a DET</span><br><span class="line">2014 NUM</span><br><span class="line">American ADJ</span><br><span class="line">action NOUN</span><br><span class="line">thriller NOUN</span><br><span class="line">film NOUN</span><br><span class="line">directed VERB</span><br><span class="line">by ADP</span><br><span class="line">Chad PROPN</span><br><span class="line">Stahelski PROPN</span><br></pre></td></tr></table></figure>
</li>
<li><p>æ‹†åˆ†ä»¤ç‰Œï¼šå°† <code>OnePlus7</code> æ‹†åˆ†æˆ <code>OnePlus</code> å’Œ <code>7</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">doc=nlp(<span class="string">&#x27;I purchased the trendy OnePlus7 &#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> doc.retokenize() <span class="keyword">as</span> retokenizer:</span><br><span class="line">    <span class="comment"># heads = [(doc[4],0),(doc[4],1)]</span></span><br><span class="line">    <span class="comment"># heads = [doc[0],doc[1]]</span></span><br><span class="line">    heads = [(doc[<span class="number">2</span>],<span class="number">1</span>),(doc[<span class="number">2</span>],<span class="number">0</span>)]</span><br><span class="line">    print(heads)</span><br><span class="line">    retokenizer.split(doc[<span class="number">4</span>],[<span class="string">&quot;OnePlus&quot;</span>,<span class="string">&quot;7&quot;</span>],heads=heads)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text)</span><br></pre></td></tr></table></figure>

<p>â“ ä¸çŸ¥é“ä¸ºå•¥ <code>heads</code> çå†™éƒ½å¯ä»¥, ä½†æ˜¯è¦æ»¡è¶³ä¸¤ä¸ªæ¡ä»¶: :one:å¦‚æœè¦æŠŠå¾…æ‹†åˆ†çš„tokenåˆ†æˆnä¸ª,é‚£ä¹ˆheadsé‡Œçš„å…ƒç´ ä¹Ÿè¦æœ‰nä¸ª,å¦åˆ™ä¼šæŠ¥é”™ :two:headsé‡Œ, docçš„ä¸‹æ ‡ä¸èƒ½è¶Šç•Œã€‚çœ‹äº†å®˜æ–¹æ–‡æ¡£ä¹Ÿæ²¡æœ‰å¼„æ˜ç™½ğŸ˜¥</p>
<p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png" loading="lazy"></p>
<p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png" alt="spacy02" loading="lazy"></p>
</li>
</ul>
<h2 id="Pipeline-components"><a href="#Pipeline-components" class="headerlink" title="Pipeline components "></a><font color=cornf>Pipeline components </font></h2><ul>
<li><p>æŸ¥çœ‹ç®¡é“ç»„ä»¶</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_sm&quot;</span>)</span><br><span class="line">print(nlp.pipe_names)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nlp.add_pipe(nlp.create_pipe(<span class="string">&#x27;textcat&#x27;</span>),before=<span class="string">&#x27;ner&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>å¦‚æœç”¨<code>juypter notebook</code>è·‘è¿™æ®µä»£ç ï¼Œåªèƒ½è·‘ä¸€æ¬¡å¦åˆ™å°±ä¼šæŠ¥é”™ï¼Œè¯´è¿™ä¸ªå·²ç»å­˜åœ¨äº†ã€‚</p>
</li>
<li><p>ç§»é™¤ç®¡é“ç»„ä»¶</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nlp.remove_pipe(<span class="string">&#x27;textcat&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>æ¢ä¸ªåå­—</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nlp.rename_pipe(old_name=<span class="string">&#x27;ner&#x27;</span>,new_name=<span class="string">&#x27;new_ner&#x27;</span>)</span><br><span class="line">nlp.pipe_names</span><br></pre></td></tr></table></figure>
</li>
<li><p>ä¸€æ ·çš„ç»“æœï¼š<code>nlp.make_doc()</code> å’Œ <code>nlp()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docs = [nlp(text) <span class="keyword">for</span> text <span class="keyword">in</span> list_of_text_data]</span><br><span class="line">print(docs)</span><br><span class="line">docs = [nlp.make_doc(text) <span class="keyword">for</span> text <span class="keyword">in</span> list_of_text_data]</span><br><span class="line">print(docs)</span><br></pre></td></tr></table></figure>
</li>
<li><p>æ¯” <code>nlp()</code> æ›´å¿«çš„å¤„ç†æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docs = list(nlp.pipe(list_of_text_data))</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><h2 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a><font color=mediumseagreen>Tutorials</font></h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.machinelearningplus.com/spacy-tutorial-nlp/">[SpaCy Tutorial â€“ Complete Writeup]</a> ä¸»è¦æ¥æºäºè¿™ç¯‡ï¼Œå†™çš„å¤ªå…¨äº†ã€‚ä¸è¿‡æœ‰äº›æ²¡çœ‹æ‡‚ã€‚</li>
</ul>
<h2 id="Official-Documentation"><a href="#Official-Documentation" class="headerlink" title="Official Documentation"></a><font color=mediumseagreen>Official Documentation</font></h2><ul>
<li><a target="_blank" rel="noopener" href="https://spacy.io/usage/visualizers">VIsualization: Displacy</a></li>
<li><a target="_blank" rel="noopener" href="https://spacy.io/usage/linguistic-features#_title">Linguistic Features</a></li>
<li><a target="_blank" rel="noopener" href="https://spacy.io/usage/rule-based-matching#_title">Rule-based matching</a></li>
<li><a target="_blank" rel="noopener" href="https://explosion.ai/demos/matcher?text=A%20match%20is%20a%20tool%20for%20starting%20a%20fire.%20Typically,%20modern%20matches%20are%20made%20of%20small%20wooden%20sticks%20or%20stiff%20paper.%20One%20end%20is%20coated%20with%20a%20material%20that%20can%20be%20ignited%20by%20frictional%20heat%20generated%20by%20striking%20the%20match%20against%20a%20suitable%20surface.%20Wooden%20matches%20are%20packaged%20in%20matchboxes,%20and%20paper%20matches%20are%20partially%20cut%20into%20rows%20and%20stapled%20into%20matchbooks.&model=en_core_web_sm&pattern=%5B%7B%22id%22:1,%22attrs%22:%5B%7B%22name%22:%22LEMMA%22,%22value%22:%22visit%22%7D,%7B%22name%22:%22POS%22,%22value%22:%22PROPN%22%7D%5D%7D%5D">Rule-based Matcher Explorer</a></li>
</ul>
<h2 id="CSDN-tutorials"><a href="#CSDN-tutorials" class="headerlink" title="CSDN tutorials"></a><font color=mediumseagreen>CSDN tutorials</font></h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Chen_he_Zhang/article/details/105345353">Spcay å®‰è£…</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u012436149/article/details/79321112">ä½¿ç”¨ spacy è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆä¸€ï¼‰</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/bmicnj/article/details/107189649?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-11.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-11.control">python spacyåº“ä½¿ç”¨æ€»ç»“ã€å¾…å®Œå–„ã€‘</a></p>
</li>
</ul>
<h2 id="Bugs"><a href="#Bugs" class="headerlink" title="Bugs"></a><font color=mediumseagreen>Bugs</font></h2><ul>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/51412095/spacy-save-custom-pipeline">Canâ€™t find factory for â€˜xxxxxxxâ€™</a></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/57536044/add-multiple-entityruler-with-spacy-valueerror-entity-ruler-already-exists-i">ValueError: â€˜entity_rulerâ€™ already exists in pipeline</a></li>
</ul>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="Donate" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">I'm so cute. Please give me money.</div><div id="qr" style="display:none;"><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090449.jpg"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090449.jpg" alt="æ”¯ä»˜å®" title="æ”¯ä»˜å®"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090448.png"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090448.png" alt="QQ æ”¯ä»˜" title="QQ æ”¯ä»˜"></a><div><span style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090450.png"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090450.png" alt="å¾®ä¿¡æ”¯ä»˜" title="å¾®ä¿¡æ”¯ä»˜"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author: </strong>ç¨‹æµ·ç›</li><li class="post-copyright-link"><strong>Post link: </strong><a href="https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/" title="Spacy tutorial">https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> unless otherwise stated.</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2021/02/06/Notes/Machine%20Learning/Naive%20Bayes%20in%20Python/" rel="prev" title="Naive Bayes in Python"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">Naive Bayes in Python</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2021/01/09/Notes/Machine%20Learning/NLP%20Relevant%20Knowledge/" rel="next" title="NLP Relevant Knowledge"><span class="post-nav-text">NLP Relevant Knowledge</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>è‹¥æ‚¨æ—  GitHub è´¦å·ï¼Œå¯ç›´æ¥åœ¨ä¸‹æ–¹åŒ¿åè¯„è®ºã€‚</span><br><span>è‹¥æ‚¨æƒ³åŠæ—¶å¾—åˆ°å›å¤æé†’ï¼Œå»ºè®®è·³è½¬ GitHub Issues è¯„è®ºã€‚</span><br><span>è‹¥æ²¡æœ‰æœ¬æ–‡ Issueï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ Comment æ¨¡ç‰ˆæ–°å»ºã€‚</span><br><a class="hty-button hty-button--raised" id="github-issues" target="_blank" rel="noopener" href="https://github.com/AllMainAshley/AllMainAshley.github.io/issues?q=is:issue+Spacy tutorial">GitHub Issues</a></div><div id="valine-container"></div><script>Yun.utils.getScript("https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js", () => {
  const valineConfig = {"enable":true,"appId":"duRJqtj9W4MnlhHrkhx0O3vb-gzGzoHsz","appKey":"7GxBY57ustzpxvpwNr39XneW","placeholder":"I want to say...","avatar":null,"pageSize":10,"visitor":false,"highlight":true,"recordIP":false,"enableQQ":true,"el":"#valine-container","lang":"en"}
  valineConfig.path = "/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/"
  new Valine(valineConfig)
}, window.Valine);</script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2020 â€“ 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> ç¨‹æµ·ç›</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v5.2.0</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.6.2</span></div><div class="live_time"><span>æœ¬åšå®¢å·²èŒèŒå“’åœ°è¿è¡Œ</span><span id="display_live_time"></span><span class="moe-text">(â—'â—¡'â—)</span><script>function blog_live_time() {
  setTimeout(blog_live_time, 1000);
  const start = new Date('2020-05-10T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = " " + passDay + " å¤© " + passHour + " å°æ—¶ " + passMinute + " åˆ† " + passSecond + " ç§’";
}
blog_live_time();
</script></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="Search"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script src="/js/search/local-search.js" defer></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-close-line"></use></svg></span></div><div class="search-input-container"><input class="search-input" id="local-search-input" type="text" placeholder="Searching..." value=""></div><div id="local-search-result"></div></div></div></body></html>